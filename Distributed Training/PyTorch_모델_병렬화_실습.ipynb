{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 전제 조건\n",
        "- Google Colab에서는 기본적으로 GPU 1개만 제공돼서,\n",
        "\"진짜 모델 병렬화\"는 안 되지만,\n",
        "구조 연습은 가능합니다.\n",
        "\n",
        "- 아래 코드는 PyTorch 공식 예제를 바탕으로,\n",
        "2개의 GPU가 있다고 가정하고 구성했어요.\n",
        "GPU가 1개일 때도 실행은 되며, 모델을 두 개의 장치로 나누는 구조 자체를 실습할 수 있습니다"
      ],
      "metadata": {
        "id": "kt4R7jnJXA_n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwx5-9tNW8Hn",
        "outputId": "689009d6-3be9-4104-843a-75d7598f9ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 가능한 GPU 수: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 사용할 장치들 확인\n",
        "device0 = torch.device(\"cuda:0\" if torch.cuda.device_count() > 0 else \"cpu\")\n",
        "device1 = torch.device(\"cuda:1\" if torch.cuda.device_count() > 1 else \"cpu\")\n",
        "\n",
        "print(\"사용 가능한 GPU 수:\", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 2층 모델 정의 - 각 층을 다른 GPU에 올릴 거예요\n",
        "class ModelParallelNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelParallelNet, self).__init__()\n",
        "        # Layer1은 device0에\n",
        "        self.layer1 = nn.Linear(1024, 2048).to(device0)\n",
        "        self.relu = nn.ReLU()\n",
        "        # Layer2는 device1에\n",
        "        self.layer2 = nn.Linear(2048, 10).to(device1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 입력은 device0에 있다고 가정\n",
        "        x = x.to(device0)\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # x를 device1로 이동\n",
        "        x = x.to(device1)\n",
        "        x = self.layer2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6YXDEZJpXk2o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성\n",
        "model = ModelParallelNet()"
      ],
      "metadata": {
        "id": "bSp6AdSJYmwU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저는 모든 파라미터를 포함해야 함\n",
        "optimizer = optim.SGD([\n",
        "    {'params': model.layer1.parameters()},\n",
        "    {'params': model.layer2.parameters()}\n",
        "], lr=0.01)\n",
        "\n",
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "NcbTzT9DYynl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가짜 입력 데이터 생성 (배치 크기 64, 입력 1024차원)\n",
        "inputs = torch.randn(64, 1024)\n",
        "labels = torch.randint(0, 10, (64,)).to(device1) # 최종 출력을 기준으로 device1에 label 위치"
      ],
      "metadata": {
        "id": "1JhH1IKUZNMN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 1회\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "outputs = model(inputs)\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "print('한 번의 학습 완료')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ROr4e71ZteT",
        "outputId": "4ec32e34-7e78-4e11-f8ae-81e13bee6465"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한 번의 학습 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 부분                   | 설명                                  |\n",
        "| -------------------- | ----------------------------------- |\n",
        "| `device0`, `device1` | GPU가 2개 있는 경우 각각 `cuda:0`, `cuda:1` |\n",
        "| `layer1` → `device0` | 첫 번째 레이어는 첫 번째 GPU에 배치              |\n",
        "| `layer2` → `device1` | 두 번째 레이어는 두 번째 GPU에 배치              |\n",
        "| `.to(device1)`       | 중간 결과를 다음 GPU로 이동                   |\n",
        "| `optimizer`          | 두 레이어의 파라미터를 모두 포함해야 함              |\n",
        "| `labels`             | 출력 레이어가 있는 `device1`에 있어야 함         |\n"
      ],
      "metadata": {
        "id": "hx85rPjPaOSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 실행 시 주의사항\n",
        "- 대부분의 Colab에서는 torch.cuda.device_count()가 1입니다.\n",
        "\n",
        "- GPU가 하나면 device1 = cuda:0과 동일하게 되고, 코드가 문제 없이 실행돼요.\n",
        "\n",
        "- 구조 자체를 이해하고 연습하는 데 목적이 있다면 Colab에서도 충분히 가능합니다.\n",
        "\n",
        "## 📦 출력 예시 (GPU 1개인 경우)\n",
        "```\n",
        "사용 가능한 GPU 수: 1\n",
        "한 번의 학습 완료\n",
        "```"
      ],
      "metadata": {
        "id": "gIbSqH3HaWzZ"
      }
    }
  ]
}