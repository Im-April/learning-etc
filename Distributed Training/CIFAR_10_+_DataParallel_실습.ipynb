{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 병렬화\n",
        "- AI모델 하나를 여러 장치에 복사해서 **각자 다른 데이터를 학습하게 하는 방법**\n",
        "\n",
        "### 쉽게 설명하면 ...\n",
        "1. 같은 AI 모델을 여러 장치에 복사\n",
        "2. 전체 데이터를 나눠서 각 장치에 조금씩(batch) 준다\n",
        "3. 각 장치는 **자기 데이터로 학습**해서, 변화량(gradient)을 계산\n",
        "4. 마지막엔 **변화량을 평균**내서, 모든 장치의 모델을 **같은 상태**로 맞춘다."
      ],
      "metadata": {
        "id": "Aad0K3hq_QrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🎯 Colab에서 안 되는가?\n",
        "- DataParallel은 2개 이상의 GPU가 있어야 동작해요.\n",
        "\n",
        "- Colab 무료 버전이나 일반 Pro 버전에서는 보통 GPU 한 개만 제공돼요.\n",
        "\n",
        "- torch.cuda.device_count() 해보면 대부분 1이 나옵니다."
      ],
      "metadata": {
        "id": "U0fAurbRRRKz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d1cUGWnY_Ob4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU 개수:\", torch.cuda.device_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDooQ3-_QTvK",
        "outputId": "02133e4d-79e5-4f55-9ac8-aec6537818c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 개수: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 전처리 및 로딩\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='.\\data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoYd4fE8AM8T",
        "outputId": "f208b976-242e-42da-f8ed-0d94519aacd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 33.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이미지를 Tensor로 바꾸고,\n",
        "- 픽셀 값을 -1 ~ 1 범위로 정규화(normalize) 해요.\n",
        "- CIFAR-10 훈련 데이터를 다운로드하고,\n",
        "- trainloader를 통해 데이터를 128개씩 묶어서(batch) 불러올 수 있게 해요"
      ],
      "metadata": {
        "id": "r087acK7RtWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 가단한 CNN ahepf wjddml (ResNet18 사용)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet18(num_classes=10)"
      ],
      "metadata": {
        "id": "tUcWwAspBXhD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 사용할 장치: GPU(cuda) 또는 CPU 자동 선택\n",
        "- 사전 정의된 ResNet-18 모델을 불러오고, 출력 클래스를 CIFAR-10에 맞게 10개로 설정"
      ],
      "metadata": {
        "id": "CubO7qXtR6sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. DataParallel로 여러 GPU 사용 설정\n",
        "if torch.cuda.device_count() > 1 :\n",
        "  print(f\"사용 가능한 GPU 수: {torch.cuda.device_count()}개\")\n",
        "  model = nn.DataParallel(model)\n",
        "\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ZFQ_-amHB8H0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GPU가 2개 이상이면, DataParallel로 감싸서 병렬 처리 가능하게 설정\n",
        "(자동으로 모델을 여러 GPU에 복사하고 병렬 학습하게 됨)\n",
        "- 모델을 GPU 또는 CPU로 이동"
      ],
      "metadata": {
        "id": "wK0nd1vCRvWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "E0s6Df86DPga"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CrossEntropyLoss: 분류 문제에서 자주 쓰는 손실 함수\n",
        "\n",
        "- SGD: 확률적 경사 하강법\n",
        "→ 학습률은 0.01, momentum은 관성값(학습 안정성에 도움)"
      ],
      "metadata": {
        "id": "rTuYVdmZSWEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 학습 루프\n",
        "for epoch in range(5) : # 에폭 5회 (전체 데이터를 5번 반복해서 학습)\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0) : # trainloader로부터 한 배치씩 불러옴\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device) # 데이터를 GPU로 이동\n",
        "\n",
        "    # 기울기 초기화\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimaze\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 통계 출력\n",
        "    running_loss += loss.item()\n",
        "    if i%100 == 99 : # 매 100 미니배치마다 출력\n",
        "      print(f\"[Epoch {epoch + 1}, Step {i + 1}] Loss: {running_loss / 100:.3f}\")\n",
        "      running_loss = 0.0\n",
        "\n",
        "\n",
        "print(\"학습 완료\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_jToowXCMrj",
        "outputId": "a8eefb33-57f3-41b0-c380-17a229753cd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Step 100] Loss: 1.889\n",
            "[Epoch 1, Step 200] Loss: 1.529\n",
            "[Epoch 1, Step 300] Loss: 1.379\n",
            "[Epoch 2, Step 100] Loss: 1.132\n",
            "[Epoch 2, Step 200] Loss: 1.098\n",
            "[Epoch 2, Step 300] Loss: 1.064\n",
            "[Epoch 3, Step 100] Loss: 0.888\n",
            "[Epoch 3, Step 200] Loss: 0.896\n",
            "[Epoch 3, Step 300] Loss: 0.862\n",
            "[Epoch 4, Step 100] Loss: 0.715\n",
            "[Epoch 4, Step 200] Loss: 0.763\n",
            "[Epoch 4, Step 300] Loss: 0.740\n",
            "[Epoch 5, Step 100] Loss: 0.555\n",
            "[Epoch 5, Step 200] Loss: 0.599\n",
            "[Epoch 5, Step 300] Loss: 0.636\n",
            "학습 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 기울기 초기화 → 예측 → 손실 계산 → 역전파 → 파라미터 업데이트\n",
        "\n",
        "- 이 과정은 각 GPU가 자신의 데이터로 따로 실행되고,\n",
        "DataParallel이 기울기를 평균내서 모든 GPU 모델을 동기화해줍니다!\n",
        "- 매 100번째 배치마다 **손실(loss)**을 출력해요. 학습 상황을 확인할 수 있어요."
      ],
      "metadata": {
        "id": "XsqYMTW1SvhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📌 핵심 요약\n",
        "- DataParallel은 모델을 복제해서 데이터 병렬화를 자동으로 처리합니다.\n",
        "\n",
        "- 각 GPU는 서로 다른 데이터(batch)를 처리하고,\n",
        "기울기를 평균 내서 모델을 동기화합니다.\n",
        "\n",
        "- 구현이 아주 간단해서 실험용 코드에 자주 사용돼요.\n",
        "\n"
      ],
      "metadata": {
        "id": "RbG1yJkZS2om"
      }
    }
  ]
}